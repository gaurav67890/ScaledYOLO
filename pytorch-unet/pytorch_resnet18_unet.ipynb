{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 13114, 'val': 2913}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "# class SimDataset(Dataset):\n",
    "#     def __init__(self, count, transform=None):\n",
    "#         self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)        \n",
    "#         self.transform = transform\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.input_images)\n",
    "    \n",
    "#     def __getitem__(self, idx):        \n",
    "#         image = self.input_images[idx]\n",
    "#         mask = self.target_masks[idx]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "        \n",
    "#         return [image, mask]\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self,  transform, subset=\"train\",damage_name='scratch'):\n",
    "        super().__init__()\n",
    "        #self.df = df\n",
    "        self.transform = transform\n",
    "        self.subset = subset\n",
    "        self.damage_name=damage_name\n",
    "        self.fn=glob.glob('../main_'+self.damage_name+'_'+self.subset+'/*.png')\n",
    "        #if self.subset == \"train\":\n",
    "        #    self.data_path = path + 'train_images/'\n",
    "        #elif self.subset == \"test\":\n",
    "        #    self.data_path = path + 'test_images/'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fn)\n",
    "    \n",
    "    def __getitem__(self, index):  \n",
    "        \n",
    "        #fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n",
    "        #img = Image.open( self.fn[index])\n",
    "        img = cv2.imread( self.fn[index])\n",
    "        #print(img.shape)\n",
    "        img = self.transform(img)\n",
    "        #print(img.shape)\n",
    "\n",
    "        #if self.subset == 'train' or self.subset == 'valid':\n",
    "        if 1>0:\n",
    "            mask = cv2.imread(self.fn[index].replace('main_',''),0)\n",
    "            #print(mask.shape)\n",
    "            mask = self.transform(mask)\n",
    "            #print(mask.shape)\n",
    "            return img, mask\n",
    "        #else: \n",
    "        #    mask = None\n",
    "        #    return img, mask\n",
    "\n",
    "\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((96,96))\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(subset=\"train\", transform=trans)\n",
    "val_set = SimDataset( subset=\"valid\",transform=trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 0.4749211 0.2118037\n",
      "0.0 1.0 0.3872319 0.4846083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7eff101cbc90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "#print('mask')\n",
    "#print(mask.shape)\n",
    "\n",
    "##print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "    \n",
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "summary(base_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
      "             ReLU-25          [-1, 128, 28, 28]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "           Conv2d-28          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-31          [-1, 128, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "             ReLU-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-43          [-1, 256, 14, 14]             512\n",
      "           Conv2d-44          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-47          [-1, 256, 14, 14]               0\n",
      "           Conv2d-48          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-49          [-1, 256, 14, 14]             512\n",
      "             ReLU-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-52          [-1, 256, 14, 14]             512\n",
      "             ReLU-53          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-54          [-1, 256, 14, 14]               0\n",
      "           Conv2d-55            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-56            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-57            [-1, 512, 7, 7]               0\n",
      "           Conv2d-58            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-59            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-60            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-63            [-1, 512, 7, 7]               0\n",
      "           Conv2d-64            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-65            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-66            [-1, 512, 7, 7]               0\n",
      "           Conv2d-67            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-68            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-69            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-70            [-1, 512, 7, 7]               0\n",
      "           Conv2d-71            [-1, 512, 7, 7]         262,656\n",
      "             ReLU-72            [-1, 512, 7, 7]               0\n",
      "         Upsample-73          [-1, 512, 14, 14]               0\n",
      "           Conv2d-74          [-1, 256, 14, 14]          65,792\n",
      "             ReLU-75          [-1, 256, 14, 14]               0\n",
      "           Conv2d-76          [-1, 512, 14, 14]       3,539,456\n",
      "             ReLU-77          [-1, 512, 14, 14]               0\n",
      "         Upsample-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          16,512\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 256, 28, 28]       1,474,816\n",
      "             ReLU-82          [-1, 256, 28, 28]               0\n",
      "         Upsample-83          [-1, 256, 56, 56]               0\n",
      "           Conv2d-84           [-1, 64, 56, 56]           4,160\n",
      "             ReLU-85           [-1, 64, 56, 56]               0\n",
      "           Conv2d-86          [-1, 256, 56, 56]         737,536\n",
      "             ReLU-87          [-1, 256, 56, 56]               0\n",
      "         Upsample-88        [-1, 256, 112, 112]               0\n",
      "           Conv2d-89         [-1, 64, 112, 112]           4,160\n",
      "             ReLU-90         [-1, 64, 112, 112]               0\n",
      "           Conv2d-91        [-1, 128, 112, 112]         368,768\n",
      "             ReLU-92        [-1, 128, 112, 112]               0\n",
      "         Upsample-93        [-1, 128, 224, 224]               0\n",
      "           Conv2d-94         [-1, 64, 224, 224]         110,656\n",
      "             ReLU-95         [-1, 64, 224, 224]               0\n",
      "           Conv2d-96          [-1, 1, 224, 224]              65\n",
      "================================================================\n",
      "Total params: 17,799,809\n",
      "Trainable params: 17,799,809\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 352.95\n",
      "Params size (MB): 67.90\n",
      "Estimated Total Size (MB): 421.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(1)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    state_dict = model.state_dict()\n",
    "    torch.save(state_dict, 'best5.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/39\n",
      "----------\n",
      "LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bce: 0.584583, dice: 0.574012, loss: 0.579297\n",
      "val: bce: 0.557367, dice: 0.589280, loss: 0.573324\n",
      "saving best model\n",
      "1m 13s\n",
      "Epoch 1/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.549155, dice: 0.529812, loss: 0.539484\n",
      "val: bce: 0.555672, dice: 0.546719, loss: 0.551195\n",
      "saving best model\n",
      "1m 14s\n",
      "Epoch 2/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.535161, dice: 0.512100, loss: 0.523630\n",
      "val: bce: 0.540794, dice: 0.501009, loss: 0.520902\n",
      "saving best model\n",
      "1m 13s\n",
      "Epoch 3/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.522684, dice: 0.497783, loss: 0.510233\n",
      "val: bce: 0.538798, dice: 0.492764, loss: 0.515781\n",
      "saving best model\n",
      "1m 14s\n",
      "Epoch 4/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.513721, dice: 0.487902, loss: 0.500812\n",
      "val: bce: 0.510614, dice: 0.491227, loss: 0.500921\n",
      "saving best model\n",
      "1m 14s\n",
      "Epoch 5/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.504231, dice: 0.478347, loss: 0.491289\n",
      "val: bce: 0.512775, dice: 0.478798, loss: 0.495786\n",
      "saving best model\n",
      "1m 13s\n",
      "Epoch 6/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.496929, dice: 0.470274, loss: 0.483602\n",
      "val: bce: 0.500862, dice: 0.480068, loss: 0.490465\n",
      "saving best model\n",
      "1m 14s\n",
      "Epoch 7/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.489118, dice: 0.461972, loss: 0.475545\n",
      "val: bce: 0.530328, dice: 0.452077, loss: 0.491203\n",
      "1m 13s\n",
      "Epoch 8/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.482018, dice: 0.454832, loss: 0.468425\n",
      "val: bce: 0.505654, dice: 0.475787, loss: 0.490720\n",
      "1m 13s\n",
      "Epoch 9/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.477622, dice: 0.449646, loss: 0.463634\n",
      "val: bce: 0.487794, dice: 0.467217, loss: 0.477505\n",
      "saving best model\n",
      "1m 14s\n",
      "Epoch 10/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.472181, dice: 0.445193, loss: 0.458687\n",
      "val: bce: 0.494005, dice: 0.461929, loss: 0.477967\n",
      "1m 13s\n",
      "Epoch 11/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.466637, dice: 0.439493, loss: 0.453065\n",
      "val: bce: 0.512167, dice: 0.456620, loss: 0.484393\n",
      "1m 14s\n",
      "Epoch 12/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.462327, dice: 0.435111, loss: 0.448719\n",
      "val: bce: 0.496105, dice: 0.455683, loss: 0.475894\n",
      "saving best model\n",
      "1m 13s\n",
      "Epoch 13/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.458798, dice: 0.432165, loss: 0.445481\n",
      "val: bce: 0.530589, dice: 0.441585, loss: 0.486087\n",
      "1m 14s\n",
      "Epoch 14/39\n",
      "----------\n",
      "LR 0.001\n",
      "train: bce: 0.453467, dice: 0.426534, loss: 0.440000\n",
      "val: bce: 0.503599, dice: 0.461887, loss: 0.482743\n",
      "1m 13s\n",
      "Epoch 15/39\n",
      "----------\n",
      "LR 0.001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 1\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in model.base_layers:\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)        \n",
    "        \n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(subset=\"test\", transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=True, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "print('input shape')\n",
    "print(inputs.shape)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
